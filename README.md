# srt-bullet-summarizer

A fast and flexible CLI tool to summarize `.srt` (subtitle) and `.txt` files into clean, bullet-point summaries using a local LLM via an OpenAI-compatible endpoint (e.g., LLaMA 3.2 with [Ollama](https://ollama.com/)).

## âœ¨ Features

- âœ… Summarizes `.srt` and `.txt` files
- âœ… Strips timestamps and indices from `.srt` files
- âœ… Uses a Map-Reduce LLM prompt strategy for long content
- âœ… Generates clear, concise bullet points
- âœ… Automatically creates output filename if not specified
- âœ… Unicode-safe file handling

## ðŸ§  How It Works

1. `.srt` files are cleaned of timestamps and sequence numbers.
2. The text is split into overlapping word chunks.
3. Each chunk is summarized using a **Map** prompt.
4. All chunk summaries are combined using a **Reduce** prompt.
5. The final bullet-point summary is saved to a `.txt` file.

## ðŸ”§ Requirements

- Rust (1.70+ recommended)
- Running local LLM API (e.g., `ollama serve`)

## ðŸš€ Usage

### Build

```sh
cargo build --release
````

### Run

```sh
# Summarize an SRT file
./srt-bullet-summarizer path/to/video_subtitles.srt

# Summarize a plain text file
./srt-bullet-summarizer path/to/notes.txt

# Specify custom output path
./srt-bullet-summarizer input.srt output/summary.txt
```

> ðŸ’¡ If no output path is provided, a file named like `input_summary.txt` will be created next to the input.

## ðŸ§ª Example

```sh
./srt-bullet-summarizer assets/sample.srt
```

Outputs:

```
assets/sample_summary.txt
```

## ðŸ“‚ File Output Convention

* Input: `lecture.srt` â†’ Output: `lecture_summary.txt`
* Input: `meeting_notes.txt` â†’ Output: `meeting_notes_summary.txt`

## ðŸ”Œ Configuration

The code uses the following default API configuration:

```rust
let config = OpenAIConfig::default()
    .with_api_base("http://localhost:11434/v1");
```

Update it if you're using a different LLM server.

## ðŸ“¦ Dependencies

* `langchain_rust`
* `serde_json`
* `regex`
* `tokio`